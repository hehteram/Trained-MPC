{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubb5PIs3LCRV"
      },
      "source": [
        "# Trained-MPC: A Private Inference by Training-Based Multiparty Computation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyIeJG8wLhB_"
      },
      "source": [
        "## Read Me!\n",
        "\n",
        "This code is provided in a Jupyter notebook file.\n",
        "\n",
        "Prerequisites: Python 3.6+  ||  PyTorch 1.0+ || NumPy\n",
        "\n",
        "Our system device: cuda\n",
        "\n",
        "## -------------------------- Input --------------------------\n",
        "\n",
        "---- Input: DatasetName, [arg1,arg2], $\\sigma$, $\\mathrm{W}$\n",
        "\n",
        "---- Default example: MNIST [Iden,Iden] 70 [[1.0,-1.0]]\n",
        "\n",
        "### details:\n",
        "\n",
        "---- DatasetName: (MNIST, Fashion-MNIST, and Cifar-10)\n",
        "\n",
        "Note: We use their datasets by using their standard training sets and testing sets. The only used preprocessings on images are Random Crop and Random Horizontal Flip on Cifar-10 training dataset and padding MNIST and Fashion-MNIST images on all sides with zeros of length $2$ to fit in a network with input size $32 \\times 32$.\n",
        "\n",
        "---- [arg1,arg2]: (The network structure) arg1: (Iden, 1, 2, ...) ----->  arg2: (Iden, 10, 11, ...)\n",
        "\n",
        "Note:  We initialize the network parameters by PyTorch default.\n",
        "\n",
        "---- $\\sigma$\n",
        "\n",
        "Note: For each value of the standard deviation of the noise, we continue the learning process for 265 epochs. We decrease the learning rate from $10^{-3}$ to $2 \\times 10^{-5}$ exponentially during the training.\n",
        "\n",
        "---- $\\mathrm{W}$: (a matrix with $T$ (the number of colluding servers) rows and $N$ (the number of servers) columns for creating $\\mathbb{P}_{\\mathbf{Z}}$)\n",
        "\n",
        "### -------------------------- Output --------------------------\n",
        "\n",
        "Reporting training accuracy during each learning epoch and testing accuracy at the end of each epoch for $\\sigma$s.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ3eg4521q7C"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import datetime\n",
        "import time\n",
        "import itertools\n",
        "\n",
        "# device\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print ('Your system: ' + str(device))"
      ],
      "metadata": {
        "id": "tC_peoUYLVoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amBcI9dyAOso"
      },
      "source": [
        "# Input parameters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# -------------- Custom examples -------------- #\n",
        "'''\n",
        "MNIST [Iden,32] 70 [[1.0,-1.0]]\n",
        "MNIST [Iden,Iden] 70 [[1.0,-1.0,10000.0]]\n",
        "MNIST [Iden,Iden] 70 [[1]]\n",
        "MNIST [Iden,32] 70 [[0.0,np.sqrt(3)/2,-np.sqrt(3)/2],[1.0,-1/2,-1/2]]\n",
        "Fashion-MNIST [Iden,32] 70 [[1.0,-1.0]]\n",
        "Cifar-10 [32,Iden] 70 [[1.0,-1.0]]\n",
        "Cifar-10 [32,128] 70 [[1,-1,10000,1.5,-1.5]]\n",
        "  .\n",
        "  .\n",
        "  .\n",
        "'''\n",
        "\n",
        "# input\n",
        "q = input('Default(d) or Custom(c) input? ')\n",
        "if q == 'c' :\n",
        "    DN,NS,Sigma,W = input('Input? ').split()\n",
        "else:\n",
        "    DN,NS,Sigma,W = 'MNIST', '[Iden,Iden]', '70', '[[1.0,-1.0]]'\n",
        "\n",
        "# type fixing\n",
        "if not(DN == 'MNIST' or DN == 'Fashion-MNIST' or DN == 'Cifar-10' or DN == 'CelebA'):\n",
        "    print ('DatasetName is false; MNIST selected as the default.')\n",
        "    DN = 'MNIST'\n",
        "NS = list(map(str, NS[1:-1].strip().split(',')))[:2]\n",
        "Sigma = float(Sigma)\n",
        "exec('W = ' + W)\n",
        "W = np.array(W,dtype=float)\n",
        "N = len(W[0,:])\n",
        "T = len(W[:,0])\n",
        "IW = np.ones((N,T+1),dtype=float)\n",
        "IW[:,1:] = W.transpose()\n",
        "\n",
        "print(DN,NS,Sigma)\n",
        "print ('N = \\n {}'.format(N))\n",
        "print ('T = \\n {}'.format(T))\n",
        "print ('[1,W^T] = \\n {}:'.format(IW))"
      ],
      "metadata": {
        "id": "kSUm0_lvEQG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "GmLgZ7ruuNiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if DN == 'MNIST':\n",
        "    # ------------ MNIST ------------ #\n",
        "    meanI = torch.tensor([0.1307])\n",
        "    stdI = torch.tensor([0.3040])\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.Pad(2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean = meanI, std = stdI),\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.Pad(2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean = meanI, std = stdI),\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform_train)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "    testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform_test)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "\n",
        "elif DN == 'Fashion-MNIST':\n",
        "    # ------------ Fashion-MNIST ------------ #\n",
        "    meanI = torch.tensor([0.2860])\n",
        "    stdI = torch.tensor([0.3205])\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.Pad(2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean = meanI, std = stdI),\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.Pad(2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean = meanI, std = stdI),\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform_train)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "    testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform_test)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "\n",
        "elif DN == 'Cifar-10':\n",
        "    # ------------ Cifar-10 ------------ #\n",
        "    meanI = torch.tensor([0.4914, 0.4822, 0.4465])\n",
        "    stdI = torch.tensor([0.2023, 0.1994, 0.2010])\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean = meanI, std = stdI),\n",
        "    ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean = meanI, std = stdI),\n",
        "    ])\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "1BAz-czVooLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "d0Jf9upVvk1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train function\n",
        "def train_function(trainloader, model, optimizer, criterion):\n",
        "    loss_sum = 0\n",
        "    correct_sum = 0\n",
        "    sample_num = 0\n",
        "\n",
        "    model.train()\n",
        "    for batch_idx, (images, labels) in enumerate(trainloader):\n",
        "        # data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        # forward\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # track\n",
        "        sample_num += labels.size(0)\n",
        "        loss_sum += (loss.item()) * labels.size(0)\n",
        "        predicted_label = torch.max(outputs.data, 1)[1]\n",
        "        correct_sum += (predicted_label == labels).sum().item()\n",
        "\n",
        "    # result\n",
        "    avg_loss = float(loss_sum) / float(sample_num)\n",
        "    avg_acc = float(correct_sum) / float(sample_num) * 100.0\n",
        "\n",
        "    return avg_loss, avg_acc\n",
        "\n",
        "\n",
        "# test function\n",
        "def test_function(testloader, model, criterion):\n",
        "    loss_sum = 0\n",
        "    correct_sum = 0\n",
        "    sample_num = 0\n",
        "    confusion_data = [[None, None]] # [target,predicted]\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, labels) in enumerate(testloader):\n",
        "            # data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            # forward\n",
        "            outputs = model(images)\n",
        "            # track\n",
        "            sample_num += labels.size(0)\n",
        "            loss_sum += (criterion(outputs, labels).item()) * labels.size(0)\n",
        "            predicted_label = torch.max(outputs.data, 1)[1]\n",
        "            correct_sum += (predicted_label == labels).sum().item()\n",
        "\n",
        "    # result\n",
        "    avg_loss = float(loss_sum) / float(sample_num)\n",
        "    avg_acc = float(correct_sum) / float(sample_num) * 100.0\n",
        "\n",
        "    return avg_loss, avg_acc\n",
        "\n",
        "\n",
        "# run function\n",
        "def run(track, trainloader, testloader, model, optimizer, criterion, epoch_num, scheduler):\n",
        "    # trackers\n",
        "    track = {'loss_train':[], 'acc_train':[], 'loss_test':[], 'acc_test':[], 'confusion_matrix':[]} if track == None else track\n",
        "\n",
        "    for epoch in range(0,epoch_num):\n",
        "        # train & test\n",
        "        loss_train, acc_train = train_function(trainloader, model, optimizer, criterion)\n",
        "        loss_test, acc_test = test_function(testloader, model, criterion)\n",
        "\n",
        "        # learning rate\n",
        "        print(f\"lr = {scheduler.get_last_lr()[0]}\")\n",
        "        scheduler.step()\n",
        "\n",
        "        # track\n",
        "        track['loss_train'].append(loss_train)\n",
        "        track['acc_train'].append(acc_train)\n",
        "        track['loss_test'].append(loss_test)\n",
        "        track['acc_test'].append(acc_test)\n",
        "        print(f'Epoch [{epoch+1}/{epoch_num}] | Loss -> Test {loss_test:.4f} Train {loss_train:.4f} | Acc -> Test {acc_test:.3f} Train {acc_train:.3f} |')\n",
        "\n",
        "    return track"
      ],
      "metadata": {
        "id": "jy3a8QiovjqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Network"
      ],
      "metadata": {
        "id": "EJqZ4qdB_7Mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "isRGB = int(DN=='Cifar-10') # MNIST and Fashion-MNIST: 0   # Cifar-10: 1\n",
        "\n",
        "if NS[1]=='Iden':\n",
        "    NS1 = 10\n",
        "else:\n",
        "    NS1 = int(NS[1])\n",
        "\n",
        "# ---------------- \\bar{g}_Pre ---------------- #\n",
        "if NS[0] == 'Iden':\n",
        "    class g_Pre(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(g_Pre, self).__init__()\n",
        "\n",
        "        def forward(self, X):\n",
        "            out = X\n",
        "            return out\n",
        "\n",
        "else:\n",
        "    class g_Pre(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(g_Pre, self).__init__()\n",
        "            self.client_L1_conv2d = nn.Conv2d(1+2*isRGB, int(NS[0]), kernel_size=5, stride=3, padding=0)\n",
        "            self.b1 = nn.BatchNorm2d(int(NS[0]))\n",
        "\n",
        "        def forward(self, X):\n",
        "            out = self.client_L1_conv2d(X)\n",
        "            out = self.b1(out)\n",
        "            out = F.relu(out)\n",
        "            return out\n",
        "\n",
        "# ---------------- f_j ---------------- #\n",
        "if NS[0] == 'Iden':\n",
        "    class f_j(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(f_j, self).__init__()\n",
        "            self.server_L1_conv2d = nn.Conv2d(1+2*isRGB, 64, kernel_size=5, stride=3, padding=0)\n",
        "            self.b1 = nn.BatchNorm2d(64)\n",
        "            self.server_L2_conv2d = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=0)\n",
        "            self.b2 = nn.BatchNorm2d(128)\n",
        "            self.server_L3_fc = nn.Linear(128 * 8 * 8, 1024)\n",
        "            self.b3 = nn.BatchNorm1d(1024)\n",
        "            self.server_L4_fc = nn.Linear(1024, NS1)\n",
        "\n",
        "        def forward(self, X):\n",
        "            out = self.server_L1_conv2d(X)\n",
        "            out = self.b1(out)\n",
        "            out = F.relu(out)\n",
        "            out = self.server_L2_conv2d(out)\n",
        "            out = self.b2(out)\n",
        "            out = F.relu(out)\n",
        "            out = out.view(out.size(0), -1)\n",
        "            out = self.server_L3_fc(out)\n",
        "            out = self.b3(out)\n",
        "            out = F.relu(out)\n",
        "            out = self.server_L4_fc(out)\n",
        "            return out\n",
        "\n",
        "else:\n",
        "    class f_j(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(f_j, self).__init__()\n",
        "            self.server_L1_conv2d = nn.Conv2d(int(NS[0]), 128, kernel_size=3, stride=1, padding=0)\n",
        "            self.b1 = nn.BatchNorm2d(128)\n",
        "            self.server_L2_fc = nn.Linear(128 * 8 * 8, 1024)\n",
        "            self.b2 = nn.BatchNorm1d(1024)\n",
        "            self.server_L3_fc = nn.Linear(1024, NS1)\n",
        "\n",
        "        def forward(self, X):\n",
        "            out = self.server_L1_conv2d(X)\n",
        "            out = self.b1(out)\n",
        "            out = F.relu(out)\n",
        "            out = out.reshape(out.size(0), -1)\n",
        "            out = self.server_L2_fc(out)\n",
        "            out = self.b2(out)\n",
        "            out = F.relu(out)\n",
        "            out = self.server_L3_fc(out)\n",
        "            return out\n",
        "\n",
        "# ---------------- \\bar{g}_Post ---------------- #\n",
        "if NS[1] == 'Iden':\n",
        "    class g_Post(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(g_Post, self).__init__()\n",
        "\n",
        "        def forward(self, X):\n",
        "            out = X\n",
        "            return out\n",
        "\n",
        "else:\n",
        "    class g_Post(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(g_Post, self).__init__()\n",
        "            self.bn = nn.BatchNorm1d(NS1)\n",
        "            self.client_L2_fc = nn.Linear(NS1, 10)\n",
        "\n",
        "        def forward(self, X):\n",
        "            out = self.bn(X)\n",
        "            out = F.relu(out)\n",
        "            out = self.client_L2_fc(out)\n",
        "            return out\n",
        "\n",
        "# ---------------- network ---------------- #\n",
        "class network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(network, self).__init__()\n",
        "        # client\n",
        "        self.client_g_Pre = g_Pre()\n",
        "        # servers\n",
        "        for j in range(N):\n",
        "            exec('self.server{} = f_j()'.format(j+1))\n",
        "        # client\n",
        "        self.client_g_Post = g_Post()\n",
        "\n",
        "    def forward(self, X):\n",
        "        # \\bar{g}_0\n",
        "        U = self.client_g_Pre(X)\n",
        "        # normalize\n",
        "        U = U - (torch.mean(U,[1,2,3],keepdim=True) * torch.ones(U.size()).to(device)).detach() # zero mean\n",
        "        U = U / (torch.std(U,[1,2,3],keepdim=True) * torch.ones(U.size()).to(device)).detach() # set variance to 1\n",
        "        # add noise (queries)\n",
        "        Q = []\n",
        "        Z = (Z_scale * torch.randn( list(U.size())+[T] )).to(device) # primary noise\n",
        "        for j in range(N):\n",
        "            q = U * IW[j,0]\n",
        "            for t in range(T):\n",
        "                q += Z[:,:,:,:,t] * IW[j,t+1]\n",
        "            normP = torch.sqrt(torch.tensor(  IW[j,0]**2  + sum((Z_scale*IW[j,1:])**2)  )).to(device) # for normalizing the queries\n",
        "            Q += [ q / normP ]\n",
        "        # answers\n",
        "        A = []\n",
        "        for j in range(N):\n",
        "            exec('A += [self.server{}(Q[{}])]'.format(j+1,j))\n",
        "        # sumA\n",
        "        sumA = A[0]\n",
        "        for j in range(1,N):\n",
        "            sumA += A[j]\n",
        "        # out\n",
        "        out = self.client_g_Post(sumA)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "tfNuAcWDooRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- model ---------------- #\n",
        "model = network().to(device)\n",
        "if device == 'cuda':\n",
        "    model = torch.nn.DataParallel(model)\n",
        "    cudnn.benchmark = True\n",
        "print(model)\n",
        "\n",
        "# -------------- criterion -------------- #\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# -------------- optimizer -------------- #\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9853)\n",
        "\n",
        "# ---------------- track ---------------- #\n",
        "track = None # is global variable"
      ],
      "metadata": {
        "id": "KxwJ6P9JWG84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run"
      ],
      "metadata": {
        "id": "YvhwF0lLWAv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_num = 265\n",
        "Z_scale = Sigma\n",
        "track = run(track, trainloader, testloader, model, optimizer, criterion, epoch_num, scheduler)\n"
      ],
      "metadata": {
        "id": "nWD2TrjlME2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "llnCShUSeqzg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}